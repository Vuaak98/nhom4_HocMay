import os
import json
import re
import logging
import sys
from typing import Dict, List, Tuple, Any, Optional
import numpy as np
import pandas as pd
from tqdm import tqdm
import joblib
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
from datetime import datetime

# Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path ƒë·ªÉ import t·ª´ c√°c module kh√°c trong src
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

# Import c√°c bi·∫øn ƒë∆∞·ªùng d·∫´n
from config import (
    DATA_DIR, RULES_PATH, STOPWORDS_PATH,
    DATA_PROCESSED_DIR, TRAIN_CLEANED_FILE, TEST_CLEANED_FILE,
    RULE_SYSTEM_PATH, TRAIN_CONFUSION_MATRIX_PATH, TEST_CONFUSION_MATRIX_PATH,
    TRAIN_FEATURES_FILE, TEST_FEATURES_FILE,
    VISUALIZATION_DIR
)

# ƒê∆∞·ªùng d·∫´n cho file JSON k·∫øt qu·∫£
TRAIN_RESULTS_JSON_PATH = os.path.join(VISUALIZATION_DIR, 'train_results.json')
TEST_RESULTS_JSON_PATH = os.path.join(VISUALIZATION_DIR, 'test_results.json')

# ƒê∆∞·ªùng d·∫´n m·ªõi cho file log mistake
MISSED_FAKES_PATH = os.path.join(VISUALIZATION_DIR, 'missed_fakes.json')
MISSED_FAKES_TRAIN_PATH = os.path.join(VISUALIZATION_DIR, 'missed_fakes_train.json')

# === C·∫•u h√¨nh logging ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('main')

class RuleSystem:
    """L·ªõp h·ªá th·ªëng lu·∫≠t k√©p: l·ªçc tin v√† tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng."""
    
    def __init__(self, rules_path: str):
        """
        Kh·ªüi t·∫°o h·ªá th·ªëng lu·∫≠t.
        
        Args:
            rules_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file JSON ch·ª©a c√°c lu·∫≠t
        """
        self.rules_path = rules_path
        self.rules = self._load_rules()
        self.components = self.rules.get('pattern_components', {})
        self.percentiles = {}
        self.is_fitted = False
        logger.info(f"‚úÖ ƒê√£ t·∫£i {len(self.components)} th√†nh ph·∫ßn lu·∫≠t t·ª´ {rules_path}")
        logger.info("‚úÖ ƒê√£ kh·ªüi t·∫°o RuleSystem")
    
    def _load_rules(self) -> Dict:
        """T·∫£i c√°c lu·∫≠t t·ª´ file JSON."""
        try:
            with open(self.rules_path, 'r', encoding='utf-8') as f:
                rules = json.load(f)
            return rules
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫£i lu·∫≠t t·ª´ {self.rules_path}: {str(e)}")
            raise
    
    def _is_match(self, text: str, component_name: str) -> bool:
        """Ki·ªÉm tra vƒÉn b·∫£n c√≥ kh·ªõp v·ªõi m·ªôt component kh√¥ng."""
        keywords = self.components.get(component_name, {}).get('keywords', [])
        return any(kw.lower() in text.lower() for kw in keywords)
    
    def _is_reliable_real_pattern(self, text: str) -> bool:
        """
        Ki·ªÉm tra xem vƒÉn b·∫£n c√≥ kh·ªõp v·ªõi m·∫´u tin t·ª©c b√°o ch√≠ kh√¥ng.
        
        Args:
            text: VƒÉn b·∫£n c·∫ßn ki·ªÉm tra
            
        Returns:
            bool: True n·∫øu kh·ªõp v·ªõi m·∫´u tin t·ª©c b√°o ch√≠
        """
        real_pattern = self.rules['patterns_for_filtering']['reliable_real_pattern']
        
        # Ki·ªÉm tra c√°c ƒëi·ªÅu ki·ªán b·∫Øt bu·ªôc
        must_have = real_pattern['must_have']
        must_not_have = real_pattern['must_not_have']
        
        # Ki·ªÉm tra t·ª´ng ƒëi·ªÅu ki·ªán b·∫Øt bu·ªôc
        has_authoritative = self._is_match(text, 'authoritative_source')
        has_informative = self._is_match(text, 'informative_tone')
        
        # Ki·ªÉm tra c√°c ƒëi·ªÅu ki·ªán c·∫•m
        has_pseudoscience = self._is_match(text, 'pseudoscience_hoax')
        has_scam = self._is_match(text, 'scam_call_to_action')
        has_spam = self._is_match(text, 'advertisement_spam')
        has_critical = self._is_match(text, 'critical_tone')
        
        # Log chi ti·∫øt cho debug
        logger.debug(f"\nKi·ªÉm tra m·∫´u tin th·∫≠t:")
        logger.debug(f"  - C√≥ ngu·ªìn tin ƒë√°ng tin c·∫≠y: {has_authoritative}")
        logger.debug(f"  - C√≥ vƒÉn phong b√°o ch√≠: {has_informative}")
        logger.debug(f"  - C√≥ d·∫•u hi·ªáu gi·∫£ khoa h·ªçc: {has_pseudoscience}")
        logger.debug(f"  - C√≥ d·∫•u hi·ªáu l·ª´a ƒë·∫£o: {has_scam}")
        logger.debug(f"  - C√≥ d·∫•u hi·ªáu spam: {has_spam}")
        logger.debug(f"  - C√≥ d·∫•u hi·ªáu ch·ªâ tr√≠ch: {has_critical}")
        
        # N·∫øu c√≥ b·∫•t k·ª≥ d·∫•u hi·ªáu x·∫•u n√†o, lo·∫°i b·ªè ngay
        if any([has_pseudoscience, has_scam, has_spam, has_critical]):
            return False
        
        # Ph·∫£i c√≥ C·∫¢ ngu·ªìn tin ƒë√°ng tin c·∫≠y V√Ä vƒÉn phong b√°o ch√≠
        if not (has_authoritative and has_informative):
            return False
        
        return True
    
    def fit(self, df: pd.DataFrame) -> 'RuleSystem':
        """
        'Hu·∫•n luy·ªán' b·ªô lu·∫≠t b·∫±ng c√°ch t√≠nh to√°n c√°c gi√° tr·ªã th·ªëng k√™ c·∫ßn thi·∫øt t·ª´ d·ªØ li·ªáu train.
        
        Args:
            df: DataFrame ch·ª©a d·ªØ li·ªáu train
            
        Returns:
            RuleSystem: ƒê·ªëi t∆∞·ª£ng RuleSystem ƒë√£ ƒë∆∞·ª£c fit
        """
        logger.info("üîÑ ƒêang t√≠nh to√°n c√°c gi√° tr·ªã th·ªëng k√™ t·ª´ d·ªØ li·ªáu train...")
        
        # T√≠nh to√°n c√°c percentiles cho c√°c c·ªôt t∆∞∆°ng t√°c
        interaction_cols = ['num_like_post', 'num_comment_post', 'num_share_post']
        for col in interaction_cols:
            if col in df.columns:
                self.percentiles[col] = {
                    'p25': df[col].quantile(0.25),
                    'p50': df[col].quantile(0.50),
                    'p75': df[col].quantile(0.75),
                    'p90': df[col].quantile(0.90),
                    'p95': df[col].quantile(0.95),
                    'p99': df[col].quantile(0.99)
                }
        
        # T√≠nh to√°n c√°c ng∆∞·ª°ng cho c√°c ƒë·∫∑c tr∆∞ng kh√°c
        if 'cleaned_message' in df.columns:
            # T·ª∑ l·ªá ch·ªØ hoa
            df['uppercase_ratio'] = df['cleaned_message'].str.findall(r'[A-Z]').str.len() / (df['cleaned_message'].str.len() + 1e-6)
            self.percentiles['uppercase_ratio'] = {
                'p75': df['uppercase_ratio'].quantile(0.75),
                'p90': df['uppercase_ratio'].quantile(0.90),
                'p95': df['uppercase_ratio'].quantile(0.95)
            }
            
            # S·ªë l∆∞·ª£ng hashtag
            df['hashtag_count'] = df['cleaned_message'].str.count('#')
            self.percentiles['hashtag_count'] = {
                'p75': df['hashtag_count'].quantile(0.75),
                'p90': df['hashtag_count'].quantile(0.90),
                'p95': df['hashtag_count'].quantile(0.95)
            }
        
        self.is_fitted = True
        logger.info("‚úÖ ƒê√£ ho√†n th√†nh vi·ªác t√≠nh to√°n c√°c gi√° tr·ªã th·ªëng k√™")
        return self
    
    def save(self, filepath: str):
        """
        L∆∞u to√†n b·ªô ƒë·ªëi t∆∞·ª£ng RuleSystem ƒë√£ ƒë∆∞·ª£c fit.
        
        Args:
            filepath: ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file
        """
        if not self.is_fitted:
            logger.warning("‚ö†Ô∏è RuleSystem ch∆∞a ƒë∆∞·ª£c fit, c√°c gi√° tr·ªã th·ªëng k√™ c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c")
        
        try:
            joblib.dump(self, filepath)
            logger.info(f"‚úÖ ƒê√£ l∆∞u ƒë·ªëi t∆∞·ª£ng RuleSystem v√†o {filepath}")
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi l∆∞u RuleSystem: {str(e)}")
            raise
    
    @classmethod
    def load(cls, filepath: str) -> 'RuleSystem':
        """
        T·∫£i m·ªôt ƒë·ªëi t∆∞·ª£ng RuleSystem ƒë√£ ƒë∆∞·ª£c l∆∞u.
        
        Args:
            filepath: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ƒë√£ l∆∞u
            
        Returns:
            RuleSystem: ƒê·ªëi t∆∞·ª£ng RuleSystem ƒë√£ ƒë∆∞·ª£c t·∫£i
        """
        try:
            model = joblib.load(filepath)
            logger.info(f"‚úÖ ƒê√£ t·∫£i ƒë·ªëi t∆∞·ª£ng RuleSystem t·ª´ {filepath}")
            return model
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫£i RuleSystem: {str(e)}")
            raise
    
    def classify_difficulty(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Ph√¢n lo·∫°i ƒë·ªô kh√≥ c·ªßa tin t·ª©c.
        
        Args:
            df: DataFrame ch·ª©a d·ªØ li·ªáu
            
        Returns:
            pd.DataFrame: DataFrame ƒë√£ ƒë∆∞·ª£c ph√¢n lo·∫°i
        """
        def get_verdict(row):
            # S·ª≠ d·ª•ng post_message g·ªëc, kh√¥ng d√πng cleaned_message
            text = str(row['post_message']).lower()
            
            # Ki·ªÉm tra c√°c ƒëi·ªÅu ki·ªán cho tin th·∫≠t d·ªÖ
            is_reliable = self._is_reliable_real_pattern(text)
            
            # Ki·ªÉm tra c√°c ƒëi·ªÅu ki·ªán cho tin kh√≥
            has_pseudoscience = self._is_match(text, 'pseudoscience_hoax')
            has_scam = self._is_match(text, 'scam_call_to_action')
            has_spam = self._is_match(text, 'advertisement_spam')
            has_critical = self._is_match(text, 'critical_tone')
            
            # Ph√¢n lo·∫°i
            if is_reliable and not (has_pseudoscience or has_scam or has_spam or has_critical):
                return 'Tin Th·∫≠t D·ªÖ'
            else:
                return 'Tin Kh√≥'
        
        df_copy = df.copy()
        df_copy['case_difficulty'] = df_copy.apply(get_verdict, axis=1)
        
        # Log th·ªëng k√™ ph√¢n lo·∫°i
        total = len(df_copy)
        easy_count = (df_copy['case_difficulty'] == 'Tin Th·∫≠t D·ªÖ').sum()
        hard_count = (df_copy['case_difficulty'] == 'Tin Kh√≥').sum()
        
        logger.info(f"\nTh·ªëng k√™ ph√¢n lo·∫°i:")
        logger.info(f"  - T·ªïng s·ªë m·∫´u: {total}")
        logger.info(f"  - Tin Th·∫≠t D·ªÖ: {easy_count} ({easy_count/total*100:.1f}%)")
        logger.info(f"  - Tin Kh√≥: {hard_count} ({hard_count/total*100:.1f}%)")
        
        return df_copy

    def extract_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        T·∫°o c√°c c·ªôt ƒë·∫∑c tr∆∞ng s·ªë t·ª´ c√°c lu·∫≠t cho m√¥ h√¨nh ML.
        
        Args:
            df: DataFrame ch·ª©a d·ªØ li·ªáu
            
        Returns:
            pd.DataFrame: DataFrame v·ªõi c√°c ƒë·∫∑c tr∆∞ng m·ªõi
        """
        if not self.is_fitted:
            logger.warning("‚ö†Ô∏è RuleSystem ch∆∞a ƒë∆∞·ª£c fit, c√°c ƒë·∫∑c tr∆∞ng c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c")
        
        df_featured = df.copy()
        # S·ª≠ d·ª•ng cleaned_message n·∫øu c√≥, ng∆∞·ª£c l·∫°i d√πng post_message
        df_featured['text_for_analysis'] = df_featured.get('cleaned_message', df_featured['post_message'])
        # Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ gi√° tr·ªã sang string v√† chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng
        df_featured['text_for_analysis'] = df_featured['text_for_analysis'].astype(str)
        df_featured['text_for_analysis_lower'] = df_featured['text_for_analysis'].str.lower()
        
        # 1. Tr√≠ch xu·∫•t ƒëi·ªÉm t·ª´ c√°c component n·ªôi dung
        for comp_name, details in self.components.items():
            feature_name = f'rule_score_{comp_name}'
            keywords = details.get('keywords', [])
            weight = details.get('weight', 0)
            
            df_featured[feature_name] = df_featured['text_for_analysis_lower'].apply(
                lambda text: sum(1 for kw in keywords if kw.lower() in str(text).lower()) * weight
            )
        
        # 2. X·ª≠ l√Ω c√°c ƒë·∫∑c tr∆∞ng ch·∫•t l∆∞·ª£ng vƒÉn b·∫£n
        df_featured['uppercase_ratio'] = df_featured['text_for_analysis'].str.findall(r'[A-Z]').str.len() / (df_featured['text_for_analysis'].str.len() + 1e-6)
        df_featured['feat_hashtag_count'] = df_featured['text_for_analysis'].str.count('#')
        df_featured['feat_url_count'] = df_featured['text_for_analysis'].str.count('http|www|<URL>')

        # 3. Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng metadata (t∆∞∆°ng t√°c)
        meta_rules = self.rules.get('metadata_rules', {})
        
        # T·ª∑ l·ªá share/like
        share_rule = meta_rules.get('high_share_ratio', {})
        ratio_threshold = share_rule.get('ratio_threshold', 2.0)
        min_likes = share_rule.get('min_likes', 50)
        weight = share_rule.get('weight', 2.0)
        
        df_featured['rule_score_high_share_ratio'] = (
            ((df_featured['num_share_post'] / (df_featured['num_like_post'] + 1)) > ratio_threshold) &
            (df_featured['num_like_post'] > min_likes)
        ).astype(int) * weight

        # S·ªë l∆∞·ª£ng hashtag
        hashtag_rule = meta_rules.get('many_hashtags', {})
        hashtag_threshold = hashtag_rule.get('hashtag_threshold', 5)
        weight = hashtag_rule.get('weight', 1.0)
        df_featured['rule_score_many_hashtags'] = (df_featured['feat_hashtag_count'] > hashtag_threshold).astype(int) * weight

        # 4. T√≠nh to√°n t·ªïng ƒëi·ªÉm fake v√† real
        fake_scores = [col for col in df_featured.columns if col.startswith('rule_score_') and col != 'rule_score_authoritative_source']
        real_scores = ['rule_score_authoritative_source']
        
        df_featured['feat_total_fake_score'] = df_featured[fake_scores].sum(axis=1)
        df_featured['feat_total_real_score'] = df_featured[real_scores].sum(axis=1)
        
        # 5. T√≠nh to√°n t·ª∑ l·ªá tin th·∫≠t
        df_featured['feat_truth_ratio'] = df_featured['feat_total_real_score'] / (df_featured['feat_total_fake_score'] + df_featured['feat_total_real_score'] + 1e-6)
        
        # 6. Ki·ªÉm tra xung ƒë·ªôt
        df_featured['feat_has_conflict'] = (
            (df_featured['feat_total_fake_score'] > 0) & 
            (df_featured['feat_total_real_score'] > 0)
        ).astype(int)
        
        # X√≥a c√°c c·ªôt t·∫°m th·ªùi
        df_featured = df_featured.drop(['text_for_analysis', 'text_for_analysis_lower'], axis=1)
        
        return df_featured

def analyze_and_save_results(df_classified: pd.DataFrame, dataset_name: str, output_path: str, cm_path: str):
    """
    Ph√¢n t√≠ch k·∫øt qu·∫£ c·ªßa B·ªò L·ªåC tr√™n c√°c tin ƒë∆∞·ª£c ph√¢n lo·∫°i l√† D·ªÑ.
    """
    logger.info(f"\n=== Ph√¢n t√≠ch ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p {dataset_name} (ch·ªâ x√©t c√°c tin D·ªÑ) ===")

    # B∆Ø·ªöC QUAN TR·ªåNG: L·ªçc ra c√°c tin ƒë√£ ƒë∆∞·ª£c b·ªô l·ªçc x·ª≠ l√Ω
    df_easy = df_classified[df_classified['case_difficulty'] != 'Tin Kh√≥'].copy()
    
    if df_easy.empty:
        logger.warning(f"Kh√¥ng c√≥ 'Tin D·ªÖ' n√†o ƒë∆∞·ª£c t√¨m th·∫•y trong t·∫≠p {dataset_name}. B·ªè qua ph√¢n t√≠ch.")
        return

    # T·∫°o nh√£n d·ª± ƒëo√°n t·ª´ k·∫øt qu·∫£ c·ªßa b·ªô l·ªçc
    # 0 l√† Th·∫≠t, 1 l√† Gi·∫£
    df_easy['predicted_label'] = df_easy['case_difficulty'].apply(lambda x: 0 if x == 'Tin Th·∫≠t D·ªÖ' else 1)

    y_true = df_easy['label']
    y_pred = df_easy['predicted_label']

    # --- B√°o c√°o ra Console ---
    report_dict = classification_report(y_true, y_pred, target_names=['Tin Th·∫≠t (0)', 'Tin Gi·∫£ (1)'], output_dict=True, zero_division=0)
    logger.info(f"\nB√°o c√°o ph√¢n lo·∫°i tr√™n c√°c tin D·ªÑ c·ªßa t·∫≠p {dataset_name}:\n" +
                classification_report(y_true, y_pred, target_names=['Tin Th·∫≠t (0)', 'Tin Gi·∫£ (1)'], zero_division=0))

    # --- V·∫Ω v√† l∆∞u Ma tr·∫≠n nh·∫ßm l·∫´n ---
    cm = confusion_matrix(y_true, y_pred, labels=[0, 1]) # Ch·ªâ ƒë·ªãnh labels ƒë·ªÉ ƒë·∫£m b·∫£o th·ª© t·ª± ƒë√∫ng
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['D·ª± ƒëo√°n Th·∫≠t', 'D·ª± ƒëo√°n Gi·∫£'], 
                yticklabels=['Th·ª±c t·∫ø Th·∫≠t', 'Th·ª±c t·∫ø Gi·∫£'])
    plt.title(f'Ma tr·∫≠n nh·∫ßm l·∫´n b·ªô l·ªçc tr√™n t·∫≠p {dataset_name} (Tin D·ªÖ)')
    plt.ylabel('Nh√£n Th·ª±c t·∫ø')
    plt.xlabel('Nh√£n D·ª± ƒëo√°n')
    plt.savefig(cm_path, bbox_inches='tight')
    plt.close()
    logger.info(f"‚úÖ ƒê√£ l∆∞u ma tr·∫≠n nh·∫ßm l·∫´n v√†o: {cm_path}")

    # --- L∆∞u k·∫øt qu·∫£ chi ti·∫øt ra file JSON ---
    results = {
        'dataset_name': dataset_name,
        'total_samples_in_set': len(df_classified),
        'easy_samples_count': len(df_easy),
        'hard_samples_count': len(df_classified) - len(df_easy),
        'easy_samples_ratio': f"{len(df_easy) / len(df_classified) * 100:.2f}%" if len(df_classified) > 0 else "0.00%",
        'classification_report_on_easy_cases': report_dict,
        'confusion_matrix_on_easy_cases': cm.tolist()
    }
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=4, ensure_ascii=False)
    logger.info(f"‚úÖ ƒê√£ l∆∞u b√°o c√°o chi ti·∫øt v√†o: {output_path}")

def run_rules_workflow(train_cleaned_df: pd.DataFrame, test_cleaned_df: pd.DataFrame) -> tuple:
    """
    H√†m workflow ch√≠nh: nh·∫≠n DataFrame ƒë√£ l√†m s·∫°ch, tr·∫£ v·ªÅ c√°c DataFrame ƒë·∫∑c tr∆∞ng v√† rule_system ƒë√£ fit.
    """
    rule_system = RuleSystem(RULES_PATH)
    rule_system.fit(train_cleaned_df)
    train_classified = rule_system.classify_difficulty(train_cleaned_df)
    test_classified = rule_system.classify_difficulty(test_cleaned_df)
    train_features = rule_system.extract_features(train_classified)
    test_features = rule_system.extract_features(test_classified)
    return train_features, test_features, rule_system, train_classified, test_classified

def main():
    # ƒê∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh
    train_cleaned_path = os.path.join('data', 'processed', 'train_cleaned.csv')
    test_cleaned_path = os.path.join('data', 'processed', 'test_cleaned.csv')
    train_cleaned_df = pd.read_csv(train_cleaned_path, encoding='utf-8')
    test_cleaned_df = pd.read_csv(test_cleaned_path, encoding='utf-8')
    train_features, test_features, rule_system, train_classified, test_classified = run_rules_workflow(train_cleaned_df, test_cleaned_df)
    # Ghi file n·∫øu ch·∫°y t·ª´ CLI
    train_features.to_csv('data/features/train_features.csv', index=False, encoding='utf-8')
    test_features.to_csv('data/features/test_features.csv', index=False, encoding='utf-8')
    print("‚úÖ ƒê√£ l∆∞u ƒë·∫∑c tr∆∞ng rule.")

if __name__ == '__main__':
    main() 